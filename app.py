import os
from dotenv import load_dotenv
load_dotenv()

import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

# â”€â”€ ã‚¢ãƒ—ãƒªã‚¿ã‚¤ãƒˆãƒ«ï¼†èª¬æ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="LLM Expert Q&A ã‚¢ãƒ—ãƒª", page_icon="ğŸ¤–")
st.title("ğŸ¤– LLM Expert Q&A ã‚¢ãƒ—ãƒª")
st.write("""
ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€è‡ªç”±ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã€ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§é¸ã‚“ã å°‚é–€å®¶ã®è¦–ç‚¹ã§
LLM ã‹ã‚‰ã®å›ç­”ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
- å°‚é–€å®¶ A: çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ
- å°‚é–€å®¶ B: ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆ

""")

# â”€â”€ LLM å‘¼ã³å‡ºã—ç”¨é–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_response(user_input: str, expert: str) -> str:
    """
    user_input: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸãƒ†ã‚­ã‚¹ãƒˆ
    expert: ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã®åå‰
    æˆ»ã‚Šå€¤: LLM ã‹ã‚‰ã®å›ç­”æ–‡å­—åˆ—
    """
    # ChatOpenAI ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆtemperature ã‚„ model_name ã¯å¿…è¦ã«å¿œã˜ã¦èª¿æ•´ï¼‰
    llm = ChatOpenAI(temperature=0.7)

    # å°‚é–€å®¶ã”ã¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åˆ‡ã‚Šæ›¿ãˆ
    if expert == "çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ":
        system_prompt = (
            "ã‚ãªãŸã¯çµŒé¨“è±Šå¯ŒãªçµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
            "ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã‚’åˆ†æã—ã€è«–ç†çš„ã‹ã¤å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"
        )
    elif expert == "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆ":
        system_prompt = (
            "ã‚ãªãŸã¯å„ªç§€ãªãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆã§ã™ã€‚"
            "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¸‚å ´ã‚„ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³æˆ¦ç•¥ã«é–¢ã—ã¦å…·ä½“çš„ã‹ã¤å‰µé€ çš„ãªææ¡ˆã‚’ã—ã¦ãã ã•ã„ã€‚"
        )
    else:
        system_prompt = "ã‚ãªãŸã¯æœ‰èƒ½ãªå°‚é–€å®¶ã§ã™ã€‚"

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_input)
    ]

    # LLM ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŠ•ã’ã¦å›ç­”ã‚’å–å¾—
    response = llm(messages)
    return response.content

# â”€â”€ UI: å°‚é–€å®¶é¸æŠï¼†å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
expert = st.radio(
    "å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„",
    ["çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ", "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆ"]
)

user_input = st.text_area("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", height=150)

# â”€â”€ é€ä¿¡ãƒœã‚¿ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.button("é€ä¿¡"):
    if not user_input.strip():
        st.warning("â— è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­â€¦"):
            answer = generate_response(user_input, expert)
        st.subheader("ğŸ’¡ å›ç­”")
        st.write(answer)
